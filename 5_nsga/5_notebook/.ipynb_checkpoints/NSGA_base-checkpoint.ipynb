{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96b1db8-5740-4619-a4ab-a44456621f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import all required libraries\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from scipy import optimize\n",
    "from scipy.interpolate import griddata\n",
    "# Pymoo imports for NSGA-II\n",
    "from pymoo.core.problem import Problem\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.termination import get_termination\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.core.callback import Callback\n",
    "# Standard libraries for file handling\n",
    "import json\n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Suppress warnings\n",
    "# Additional math and stats\n",
    "import math\n",
    "from statistics import mean, median\n",
    "\n",
    "# Set up paths to your scripts and data directories\n",
    "try:\n",
    "    # Get the parent directory of the current notebook\n",
    "    notebook_dir = Path.cwd()\n",
    "    project_root = notebook_dir.parent.parent  # Two levels up from the notebook\n",
    "    \n",
    "    # Point to your scripts folder - new path structure\n",
    "    scripts_dir = project_root / \"5_nsga_scripts\" / \"NSGA_base\"\n",
    "    \n",
    "    # Point to data and results directories\n",
    "    data_dir = project_root.parent / \"data\"\n",
    "    results_dir = project_root / \"5_nsga_results\"\n",
    "    \n",
    "    # Create results directory if it doesn't exist\n",
    "    results_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    print(f\"Project root: {project_root}\")\n",
    "    print(f\"Scripts directory: {scripts_dir}\")\n",
    "    print(f\"Data directory: {data_dir}\")\n",
    "    print(f\"Results directory: {results_dir}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error setting up directories: {e}\")\n",
    "    raise\n",
    "\n",
    "# Add scripts directory to path\n",
    "if not scripts_dir.exists():\n",
    "    raise FileNotFoundError(f\"Scripts directory not found at: {scripts_dir}\")\n",
    "\n",
    "sys.path.insert(0, str(scripts_dir))\n",
    "\n",
    "# Import custom modules\n",
    "try:\n",
    "    # Import configuration\n",
    "    from config import *\n",
    "    \n",
    "    # Import core modules\n",
    "    from battery import simulate_battery_dispatch\n",
    "    from pv import simulate_multi_year_pv, load_demand_profile, create_30_year_profile\n",
    "    from fin import compute_financials\n",
    "    from obj import evaluate_solution\n",
    "    from results import setup_results_directory, create_pareto_plot\n",
    "    \n",
    "    print(\"All modules imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing modules: {e}\")\n",
    "    print(f\"Files in scripts directory: {[f.name for f in scripts_dir.iterdir() if f.is_file()]}\")\n",
    "    raise\n",
    "\n",
    "print(\"All imports completed successfully\")\n",
    "\n",
    "# Create a new numbered subfolder for this run's results\n",
    "run_dir = setup_results_directory(results_dir)\n",
    "print(f\"Results will be saved to: {run_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082308dc-2999-4881-82b4-8971a8b70b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load Data Files and Configuration\n",
    "print(\"Loading data files and configuration...\")\n",
    "\n",
    "# Verify data directory\n",
    "data_dir = Path(config.DATA_DIR)\n",
    "if not data_dir.exists():\n",
    "    alternatives = [\n",
    "        project_root / \"data\",\n",
    "        project_root.parent / \"Battery_Optimisation\" / \"data\",\n",
    "        Path.cwd() / \"data\"\n",
    "    ]\n",
    "    \n",
    "    for alt in alternatives:\n",
    "        if alt.exists():\n",
    "            data_dir = alt\n",
    "            break\n",
    "    else:\n",
    "        print(\"\\nWARNING: Data directory not found at expected locations.\")\n",
    "        print(\"Please enter the absolute path to your data directory:\")\n",
    "        user_path = input().strip()\n",
    "        data_dir = Path(user_path)\n",
    "        if not data_dir.exists():\n",
    "            raise FileNotFoundError(f\"Data directory not found: {data_dir}\\nPlease check your path and try again.\")\n",
    "\n",
    "print(f\"Using data directory: {data_dir}\")\n",
    "\n",
    "# Find weather files\n",
    "print(\"\\nLooking for weather files...\")\n",
    "weather_files = []\n",
    "\n",
    "for filename in config.DESIRED_WEATHER_FILES:\n",
    "    file_path = data_dir / filename\n",
    "    if file_path.exists():\n",
    "        weather_files.append(str(file_path))\n",
    "        print(f\"  ✔ Found: {filename}\")\n",
    "    else:\n",
    "        print(f\"  ❌ Missing: {filename}\")\n",
    "\n",
    "if len(weather_files) < 3:\n",
    "    # If we didn't find all the specific files, look for any .epw files\n",
    "    print(\"\\nSearching for alternative .epw files...\")\n",
    "    available_epw = sorted(list(data_dir.glob(\"*.epw\")))\n",
    "    \n",
    "    if available_epw:\n",
    "        while len(weather_files) < 3 and available_epw:\n",
    "            for epw in available_epw:\n",
    "                if str(epw) not in weather_files:\n",
    "                    weather_files.append(str(epw))\n",
    "                    print(f\"  Using: {epw.name}\")\n",
    "                    break\n",
    "    \n",
    "    # If we still don't have 3 weather files, we need to check the path\n",
    "    if len(weather_files) < 3:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Could not find the required weather files: {', '.join(config.DESIRED_WEATHER_FILES)}\\n\"\n",
    "            f\"Please ensure these files exist in: {data_dir}\"\n",
    "        )\n",
    "\n",
    "# Find demand file\n",
    "print(\"\\nLooking for demand file...\")\n",
    "demand_file = None\n",
    "\n",
    "# First try the primary file specified in DEMAND_FILE_CONFIG\n",
    "primary_file = data_dir / config.DEMAND_FILE_CONFIG[\"primary_file\"]\n",
    "if primary_file.exists():\n",
    "    demand_file = primary_file\n",
    "    print(f\"  ✔ Found primary demand file: {primary_file.name}\")\n",
    "else:\n",
    "    # Try alternative files\n",
    "    for filename in config.ALTERNATIVE_DEMAND_FILES:\n",
    "        file_path = data_dir / filename\n",
    "        if file_path.exists():\n",
    "            demand_file = file_path\n",
    "            print(f\"  ✔ Found alternative demand file: {filename}\")\n",
    "            break\n",
    "            \n",
    "if demand_file is None:\n",
    "    # List available CSV files\n",
    "    csv_files = sorted(list(data_dir.glob(\"*.csv\")))\n",
    "    if csv_files:\n",
    "        print(\"\\nNo demand file found with expected name. Available CSV files:\")\n",
    "        for csv in csv_files:\n",
    "            print(f\"  - {csv.name}\")\n",
    "        # Ask user to select a file\n",
    "        print(\"\\nPlease enter the number of the CSV file to use for demand data:\")\n",
    "        for i, csv in enumerate(csv_files):\n",
    "            print(f\"  {i+1}. {csv.name}\")\n",
    "        selection = int(input().strip()) - 1\n",
    "        if 0 <= selection < len(csv_files):\n",
    "            demand_file = csv_files[selection]\n",
    "            print(f\"Using {demand_file.name} as demand file\")\n",
    "        else:\n",
    "            raise ValueError(\"Invalid selection\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"No CSV files found in {data_dir}\")\n",
    "\n",
    "# Display configuration summary\n",
    "print(\"\\nConfiguration summary:\")\n",
    "print(f\"  • Data directory: {data_dir}\")\n",
    "print(f\"  • Demand file: {demand_file.name}\")\n",
    "print(f\"  • Weather files: {', '.join([Path(wf).name for wf in weather_files])}\")\n",
    "\n",
    "# Display existing PV system details\n",
    "print(\"\\nExisting PV system:\")\n",
    "existing_pv = config.EXISTING_PV\n",
    "print(f\"  - {existing_pv['name']}: {existing_pv['system_capacity_kw']} kW, \" \n",
    "      f\"Tilt: {existing_pv['tilt']}°, Azimuth: {existing_pv['azimuth']}°, \"\n",
    "      f\"Shading: {existing_pv['shading']}%\")\n",
    "\n",
    "# Display new PV options\n",
    "print(\"\\nNew PV options:\")\n",
    "for option in config.PV_OPTIONS:\n",
    "    max_capacity = option['max_capacity_kw']\n",
    "    # Format \"inf\" nicely\n",
    "    max_capacity_str = f\"{max_capacity:.1f}\" if max_capacity != float('inf') else \"unlimited\"\n",
    "    print(f\"  - {option['name']}: Max {max_capacity_str} kW, \"\n",
    "          f\"Tilt: {option['tilt']}°, Azimuth: {option['azimuth']}°, \"\n",
    "          f\"Shading: {option['shading']}%, Cost multiplier: {option['cost_multiplier']}\")\n",
    "\n",
    "# Continue with other configuration details\n",
    "print(f\"\\n  • Discount rate: {config.DISCOUNT_RATE * 100}%\")\n",
    "print(f\"  • Electricity rates: Peak: ${config.ELECTRICITY_RATES['peak']}/kWh, Off-peak: ${config.ELECTRICITY_RATES['offpeak']}/kWh\")\n",
    "print(f\"  • Export rate: ${config.ELECTRICITY_RATES['export']}/kWh\")\n",
    "print(f\"  • Battery efficiency: {config.BATTERY_EFF * 100}%\")\n",
    "\n",
    "# Add battery control mode display\n",
    "if hasattr(config, 'BATTERY_CONTROL'):\n",
    "    print(f\"  • Battery control mode: {'Advanced' if config.BATTERY_CONTROL['peak_reserve_soc'] > config.MIN_SOC else 'Basic'}\")\n",
    "    if config.BATTERY_CONTROL['peak_reserve_soc'] > config.MIN_SOC:\n",
    "        print(f\"    - Peak reserve: {config.BATTERY_CONTROL['peak_reserve_soc']*100:.0f}% SOC, {config.BATTERY_CONTROL['peak_reserve_hours']} hours before peak\")\n",
    "        print(f\"    - Off-peak minimum SOC: {config.BATTERY_CONTROL['off_peak_min_soc']*100:.0f}%\")\n",
    "\n",
    "print(f\"  • Project lifetime: {config.PROJECT_LIFETIME} years\")\n",
    "print(f\"  • Peak periods: AEDT (Oct-Mar): {config.PEAK_PERIODS['AEDT_period']['start_hour']}:00-{config.PEAK_PERIODS['AEDT_period']['end_hour']}:00, AEST (Apr-Sep): {config.PEAK_PERIODS['AEST_period']['start_hour']}:00-{config.PEAK_PERIODS['AEST_period']['end_hour']}:00\")\n",
    "print(f\"  • Optimization: {config.POPULATION_SIZE} population, {config.N_GENERATIONS} generations\")\n",
    "\n",
    "# Add sensitivity analysis parameters\n",
    "print(\"\\nSensitivity Analysis Parameters:\")\n",
    "print(f\"  • Inflation: {config.MAINTENANCE_INFLATION*100}% (sensitivity range: 2-5%)\")\n",
    "print(f\"  • Discount rate: {config.DISCOUNT_RATE*100}% (sensitivity range: 5-11%)\")\n",
    "print(f\"  • Battery cost: ${config.BATTERY_COST_FORMULA['base_cost']}/kWh (sensitivity: ±20%)\")\n",
    "print(f\"  • PV cost: ${config.PV_COST_FORMULA['base_cost']}/kW (sensitivity: ±15%)\")\n",
    "print(f\"  • Export rate: ${config.ELECTRICITY_RATES['export']}/kWh (sensitivity: try 0.05-0.10)\")\n",
    "print(f\"  • Project lifetime: {config.PROJECT_LIFETIME} years (sensitivity: try 20, 25 years)\")\n",
    "\n",
    "# Weather file scenarios\n",
    "print(\"\\nWeather scenarios available:\")\n",
    "for scenario, files in config.WEATHER_SCENARIOS.items():\n",
    "    if scenario == 'baseline':\n",
    "        print(f\"  • {scenario.capitalize()}: {', '.join([Path(f).name for f in files])} (current)\")\n",
    "    else:\n",
    "        print(f\"  • {scenario.capitalize()}: {', '.join([Path(f).name for f in files])}\")\n",
    "\n",
    "if config.BATTERY_CHARGING_CONTROL['enabled']:\n",
    "    print(f\"\\nBattery charging restricted to: {config.BATTERY_CHARGING_CONTROL['allowed_hours']['start_hour']}:00-{config.BATTERY_CHARGING_CONTROL['allowed_hours']['end_hour']}:00\")\n",
    "else:\n",
    "    print(f\"\\nBattery charging: Unrestricted (sensitivity: try time-of-day restrictions)\")\n",
    "\n",
    "if config.BATTERY_REBATES['enabled']:\n",
    "    if config.BATTERY_REBATES['fixed_amount'] > 0:\n",
    "        print(f\"Battery rebate: Fixed ${config.BATTERY_REBATES['fixed_amount']}\")\n",
    "    else:\n",
    "        print(f\"Battery rebate: {config.BATTERY_REBATES['percentage']*100}% up to ${config.BATTERY_REBATES['cap']}\")\n",
    "else:\n",
    "    print(f\"Battery rebates: None (sensitivity: try fixed and percentage rebates)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a2756d-96e9-44c8-938a-77bd67e28c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Load Demand Data and Create 30-Year Profile\n",
    "print(\"\\nLoading demand data and creating profiles...\")\n",
    "\n",
    "def load_demand_profile(csv_path: Path) -> dict:\n",
    "    \"\"\"Load demand profile from CSV file.\"\"\"\n",
    "    # Get column mappings from config\n",
    "    timestamp_col = config.DEMAND_FILE_CONFIG[\"columns\"][\"timestamp\"]\n",
    "    pv_gen_col = config.DEMAND_FILE_CONFIG[\"columns\"][\"pv_generation\"]\n",
    "    consumption_col = config.DEMAND_FILE_CONFIG[\"columns\"][\"consumption\"]\n",
    "    date_format = config.DEMAND_FILE_CONFIG[\"date_format\"]\n",
    "    \n",
    "    # Load the CSV file\n",
    "    raw = pd.read_csv(csv_path, parse_dates=[timestamp_col], dayfirst=True)\n",
    "    \n",
    "    # Drop rows with NaN timestamps right away\n",
    "    raw = raw.dropna(subset=[timestamp_col])\n",
    "    print(f\"CSV loaded with {len(raw)} valid rows\")\n",
    "    \n",
    "    # Create Series with timestamp index for both demand and generation\n",
    "    consumption = pd.Series(raw[consumption_col].values, index=raw[timestamp_col])\n",
    "    generation = pd.Series(raw[pv_gen_col].values, index=raw[timestamp_col])\n",
    "    \n",
    "    # Check for duplicate timestamps\n",
    "    dup_count = consumption.index.duplicated().sum()\n",
    "    if dup_count:\n",
    "        print(f\"⚠️ Dropping {dup_count} duplicate timestamps\")\n",
    "        consumption = consumption[~consumption.index.duplicated(keep='first')]\n",
    "        generation = generation[~generation.index.duplicated(keep='first')]\n",
    "    \n",
    "    # Build the expected half-hour index for entire year (no Feb 29)\n",
    "    year = consumption.index.min().year\n",
    "    start = pd.Timestamp(year, 1, 1, 0, 0)\n",
    "    end = pd.Timestamp(year, 12, 31, 23, 30)\n",
    "    expected = pd.date_range(start, end, freq=\"30min\")\n",
    "    expected = expected[~((expected.month==2) & (expected.day==29))]\n",
    "    \n",
    "    # Reindex to ensure complete coverage\n",
    "    consumption = consumption.reindex(expected)\n",
    "    generation = generation.reindex(expected)\n",
    "    \n",
    "    # Fill missing values\n",
    "    missing_consumption = consumption.isna().sum()\n",
    "    missing_generation = generation.isna().sum()\n",
    "    \n",
    "    if missing_consumption:\n",
    "        print(f\"⚠️ Filling {missing_consumption} missing consumption points with 0\")\n",
    "        consumption = consumption.fillna(0.0)\n",
    "        \n",
    "    if missing_generation:\n",
    "        print(f\"⚠️ Filling {missing_generation} missing generation points with 0\")\n",
    "        generation = generation.fillna(0.0)\n",
    "    \n",
    "    # Final sanity check\n",
    "    assert len(consumption) == 17520, f\"Got {len(consumption)} consumption points, expected 17520\"\n",
    "    assert len(generation) == 17520, f\"Got {len(generation)} generation points, expected 17520\"\n",
    "    \n",
    "    # Return both series\n",
    "    return {\n",
    "        'consumption': consumption,\n",
    "        'generation': generation\n",
    "    }\n",
    "\n",
    "def create_30_year_profile(one_year_series: pd.Series, years=30, start_year=2025, apply_growth=False) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Create a 30-year profile from a 1-year series.\n",
    "    \n",
    "    Args:\n",
    "        one_year_series: Base year demand series\n",
    "        years: Number of years to create\n",
    "        start_year: Starting year for the profile\n",
    "        apply_growth: If True, apply demand growth according to config settings\n",
    "        \n",
    "    Returns:\n",
    "        Pandas Series with the multi-year profile\n",
    "    \"\"\"\n",
    "    original_year = one_year_series.index[0].year\n",
    "    all_data = []\n",
    "    \n",
    "    for year_offset in range(years):\n",
    "        # Copy the data for this year\n",
    "        year_data = one_year_series.copy()\n",
    "        \n",
    "        # Apply demand growth if enabled\n",
    "        if apply_growth and config.DEMAND_GROWTH['enabled']:\n",
    "            decade = year_offset // 10  # Calculate which decade we're in\n",
    "            \n",
    "            if config.DEMAND_GROWTH['pattern'] == 'decade':\n",
    "                # Apply growth by decade (e.g., years 0-9 = 1x, years 10-19 = 1.1x, etc.)\n",
    "                growth_multiplier = 1 + (decade * config.DEMAND_GROWTH['percent_per_decade'] / 100)\n",
    "                year_data = year_data * growth_multiplier\n",
    "                \n",
    "            elif config.DEMAND_GROWTH['pattern'] == 'annual':\n",
    "                # Apply compounding annual growth (more complex)\n",
    "                annual_rate = (1 + config.DEMAND_GROWTH['percent_per_decade'] / 100) ** (1/10) - 1\n",
    "                growth_multiplier = (1 + annual_rate) ** year_offset\n",
    "                year_data = year_data * growth_multiplier\n",
    "        \n",
    "        # Create index for this specific year\n",
    "        target_year = start_year + year_offset\n",
    "        year_start = pd.Timestamp(target_year, 1, 1, 0, 0)\n",
    "        year_end = pd.Timestamp(target_year, 12, 31, 23, 30)\n",
    "        year_range = pd.date_range(start=year_start, end=year_end, freq=\"30min\")\n",
    "        \n",
    "        # Remove Feb 29 if it's a leap year\n",
    "        year_range = year_range[~((year_range.month == 2) & (year_range.day == 29))]\n",
    "        \n",
    "        # Make sure it has the right number of points\n",
    "        assert len(year_range) == len(one_year_series), f\"Year {target_year} has {len(year_range)} points, expected {len(one_year_series)}\"\n",
    "        \n",
    "        # Assign the new index and add to our list\n",
    "        year_data.index = year_range\n",
    "        all_data.append(year_data)\n",
    "    \n",
    "    # Concatenate all years\n",
    "    return pd.concat(all_data)\n",
    "\n",
    "# Load the demand data\n",
    "print(f\"\\nLoading demand data from: {demand_file}\")\n",
    "demand_data = load_demand_profile(demand_file)\n",
    "\n",
    "# Display summary information\n",
    "one_year_demand = demand_data['consumption']\n",
    "one_year_generation = demand_data['generation']\n",
    "\n",
    "print(f\"\\nDemand data summary:\")\n",
    "print(f\"  • Time period: {one_year_demand.index[0]} to {one_year_demand.index[-1]}\")\n",
    "print(f\"  • Total annual consumption: {one_year_demand.sum():.2f} kWh\")\n",
    "print(f\"  • Total annual generation: {one_year_generation.sum():.2f} kWh\")\n",
    "print(f\"  • Time step: {(one_year_demand.index[1] - one_year_demand.index[0]).total_seconds()/60:.0f} minutes\")\n",
    "\n",
    "# Create 30-year profiles\n",
    "print(\"\\nCreating 30-year profiles for simulation...\")\n",
    "\n",
    "# Check if demand growth is enabled\n",
    "demand_growth_enabled = config.DEMAND_GROWTH['enabled']\n",
    "if demand_growth_enabled:\n",
    "    pattern = \"decade\" if config.DEMAND_GROWTH['pattern'] == 'decade' else \"year\"\n",
    "    print(f\"Applying demand growth of {config.DEMAND_GROWTH['percent_per_decade']}% per {pattern}\")\n",
    "\n",
    "# Create demand profile with potential growth\n",
    "demand_profile = create_30_year_profile(\n",
    "    one_year_demand, \n",
    "    years=config.PROJECT_LIFETIME, \n",
    "    start_year=2025,\n",
    "    apply_growth=demand_growth_enabled\n",
    ")\n",
    "\n",
    "# Create PV profile (no growth - PV output doesn't grow with time)\n",
    "existing_pv_profile = create_30_year_profile(\n",
    "    one_year_generation, \n",
    "    years=config.PROJECT_LIFETIME, \n",
    "    start_year=2025,\n",
    "    apply_growth=False\n",
    ")\n",
    "\n",
    "# Calculate baseline metrics for comparison\n",
    "print(\"\\nCalculating baseline metrics with existing PV:\")\n",
    "annual_import_with_pv = max(0, one_year_demand.sum() - one_year_generation.sum()) \n",
    "annual_export_with_pv = max(0, one_year_generation.sum() - one_year_demand.sum())\n",
    "self_consumption_ratio = min(one_year_generation.sum(), one_year_demand.sum()) / one_year_generation.sum()\n",
    "\n",
    "print(f\"  • Annual grid import with existing PV: {annual_import_with_pv:.2f} kWh\")\n",
    "print(f\"  • Annual grid export with existing PV: {annual_export_with_pv:.2f} kWh\")\n",
    "print(f\"  • Self-consumption ratio: {self_consumption_ratio*100:.1f}%\")\n",
    "\n",
    "# Store baseline metrics for later comparison\n",
    "baseline_metrics = {\n",
    "    'annual_consumption': one_year_demand.sum(),\n",
    "    'annual_historical_pv': one_year_generation.sum(),\n",
    "    'annual_import_with_pv': annual_import_with_pv,\n",
    "    'annual_export_with_pv': annual_export_with_pv,\n",
    "    'self_consumption_ratio': self_consumption_ratio\n",
    "}\n",
    "\n",
    "# Show total 30-year profiles with growth effect if enabled\n",
    "print(\"\\n30-year profiles created:\")\n",
    "print(f\"  • Time steps: {len(demand_profile)}\")\n",
    "print(f\"  • Date range: {demand_profile.index[0]} → {demand_profile.index[-1]}\")\n",
    "print(f\"  • Total 30-year demand: {demand_profile.sum():.2f} kWh\")\n",
    "print(f\"  • Total 30-year existing PV generation: {existing_pv_profile.sum():.2f} kWh\")\n",
    "\n",
    "if demand_growth_enabled:\n",
    "    # Calculate the growth effect\n",
    "    first_year_demand = demand_profile[demand_profile.index.year == 2025].sum()\n",
    "    last_year_demand = demand_profile[demand_profile.index.year == (2025 + config.PROJECT_LIFETIME - 1)].sum()\n",
    "    growth_factor = last_year_demand / first_year_demand\n",
    "    print(f\"  • Demand growth effect: Year 1 = {first_year_demand:.2f} kWh, Year {config.PROJECT_LIFETIME} = {last_year_demand:.2f} kWh\")\n",
    "    print(f\"  • Total growth factor over {config.PROJECT_LIFETIME} years: {growth_factor:.2f}x\")\n",
    "\n",
    "# Memory optimization for large datasets\n",
    "print(\"\\nOptimizing memory usage for 30-year simulation...\")\n",
    "demand_profile = demand_profile.astype(np.float32)\n",
    "existing_pv_profile = existing_pv_profile.astype(np.float32)\n",
    "print(\"Memory optimization complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a726436-487a-4c43-8473-ffa73b1ee4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Test Utility Functions for the Optimization\n",
    "print(\"Testing utility functions for optimization...\")\n",
    "\n",
    "# Import necessary modules\n",
    "from fin import calculate_pv_cost\n",
    "from pv import allocate_pv_capacity\n",
    "\n",
    "# Test PV cost function\n",
    "print(\"\\nTesting PV cost function:\")\n",
    "test_capacities = [5, 10, 20, 30, 40, 50, 100]\n",
    "print(\"Capacity (kW) | Cost per kW ($)\")\n",
    "print(\"--------------------------\")\n",
    "for cap in test_capacities:\n",
    "    cost = calculate_pv_cost(cap)\n",
    "    print(f\"{cap:12.1f} | ${cost:10.2f}\")\n",
    "\n",
    "# Test ground-mounted with premium\n",
    "print(f\"\\nGround-mounted PV with {config.PV_OPTIONS[2]['cost_multiplier']*100:.0f}% premium:\")\n",
    "print(\"Capacity (kW) | Cost per kW ($)\")\n",
    "print(\"--------------------------\")\n",
    "for cap in [10, 30, 50]:\n",
    "    cost = calculate_pv_cost(cap, cost_multiplier=config.PV_OPTIONS[2]['cost_multiplier'])\n",
    "    print(f\"{cap:12.1f} | ${cost:10.2f}\")\n",
    "\n",
    "# Test PV allocation\n",
    "print(\"\\nTesting PV allocation:\")\n",
    "print(\"Testing with 50 kW total capacity...\")\n",
    "allocated = allocate_pv_capacity(50, config.PV_OPTIONS)\n",
    "print(\"Allocation results:\")\n",
    "for pv in allocated:\n",
    "    print(f\"  - {pv['name']}: {pv['system_capacity_kw']:.2f} kW\")\n",
    "\n",
    "print(\"\\nUtility functions tested successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6470f2f-4634-402c-9825-0583423ab8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Simulate existing PV system\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "print(\"\\nSimulating 30-year PV generation for existing system...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Get configuration parameters\n",
    "start_years = getattr(config, 'START_YEARS', [2025, 2040, 2050])\n",
    "existing_pv_system = config.EXISTING_PV\n",
    "\n",
    "# Simulate existing PV system\n",
    "pv_profile = simulate_multi_year_pv(\n",
    "    weather_files=weather_files,\n",
    "    roof_params=[existing_pv_system],\n",
    "    repeats_per_file=10,\n",
    "    start_years=start_years\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"PV simulation completed in {elapsed:.1f} seconds ({timedelta(seconds=int(elapsed))})\")\n",
    "print(f\"   • PV steps: {len(pv_profile)}\")\n",
    "print(f\"   • Date range: {pv_profile.index[0]} → {pv_profile.index[-1]}\")\n",
    "print(f\"   • Total generation: {pv_profile['simulated_kwh'].sum():.2f} kWh\")\n",
    "\n",
    "# Optimize memory usage for large datasets\n",
    "print(\"\\nOptimizing memory usage for 30-year simulation...\")\n",
    "# Convert float64 to float32 to save memory (reduces memory footprint by ~50%)\n",
    "pv_profile['simulated_kwh'] = pv_profile['simulated_kwh'].astype(np.float32)\n",
    "demand_profile = demand_profile.astype(np.float32)\n",
    "print(\"Memory optimization complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf00aa5a-b306-475d-8c63-93fe94f311a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Verify baseline costs and setup\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import gc\n",
    "\n",
    "print(\"\\nVerifying baseline costs and simulation setup...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Display baseline costs from config\n",
    "print(f\"Annual no-PV cost: ${config.ANNUAL_NO_PV_COST:,.2f}\")\n",
    "print(f\"Annual PV-only cost: ${config.ANNUAL_PV_ONLY_COST:,.2f}\")\n",
    "print(f\"Annual savings from PV alone: ${config.ANNUAL_NO_PV_COST - config.ANNUAL_PV_ONLY_COST:,.2f}\")\n",
    "\n",
    "# Calculate 30-year costs with escalation\n",
    "escalation_factor = sum((1 + config.ELECTRICITY_PRICE_ESCALATION)**year for year in range(config.PROJECT_LIFETIME))\n",
    "no_pv_total_cost = config.ANNUAL_NO_PV_COST * escalation_factor\n",
    "pv_only_total_cost = config.ANNUAL_PV_ONLY_COST * escalation_factor\n",
    "\n",
    "print(f\"\\n30-year costs with {config.ELECTRICITY_PRICE_ESCALATION*100:.0f}% annual escalation:\")\n",
    "print(f\"  • No-PV baseline: ${no_pv_total_cost:,.2f}\")\n",
    "print(f\"  • PV-only baseline: ${pv_only_total_cost:,.2f}\")\n",
    "print(f\"  • 30-year savings from PV alone: ${no_pv_total_cost - pv_only_total_cost:,.2f}\")\n",
    "\n",
    "# Clear memory before verification simulation\n",
    "print(\"\\nClearing memory cache before verification simulation...\")\n",
    "gc.collect()\n",
    "\n",
    "print(\"Running verification simulation with 0 kWh battery...\")\n",
    "# Simulate with existing PV, no battery to verify\n",
    "disp0, totals0 = simulate_battery_dispatch(\n",
    "    pv_gen=pv_profile['simulated_kwh'],\n",
    "    demand=demand_profile,\n",
    "    battery_kwh=0.0,\n",
    "    roundtrip_eff=config.BATTERY_EFF,\n",
    "    min_soc_pct=config.MIN_SOC,\n",
    "    annual_deg_rate=config.BATTERY_DEGRADATION,\n",
    "    grid_emission_rate=config.GRID_EMISSIONS,\n",
    "    config=config\n",
    ")\n",
    "print(\"✅ Verification simulation completed successfully\")\n",
    "\n",
    "# Display key metrics from verification simulation\n",
    "print(\"\\nVerification simulation results:\")\n",
    "print(f\"  • Total demand: {totals0['total_demand']:,.2f} kWh\")\n",
    "print(f\"  • Grid import: {totals0['total_grid_import_peak'] + totals0['total_grid_import_offpeak']:,.2f} kWh\")\n",
    "print(f\"  • PV export: {totals0['total_pv_export']:,.2f} kWh\")\n",
    "print(f\"  • Self-consumption rate: {totals0['self_consumption_rate']*100:.1f}%\")\n",
    "print(f\"  • Renewable fraction: {totals0['renewable_fraction']*100:.1f}%\")\n",
    "\n",
    "# Final memory cleanup before optimization\n",
    "print(\"\\nFinal memory cleanup before optimization...\")\n",
    "gc.collect()\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"Verification completed in {elapsed:.1f} seconds ({timedelta(seconds=int(elapsed))})\")\n",
    "print(\"Ready to proceed with optimization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54620602-b2f7-4c5f-9488-63de63fd768b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Set up the NSGA-II optimization problem\n",
    "from obj import BatteryPVOptimizationProblem\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.termination import get_termination\n",
    "\n",
    "print(\"Setting up optimization problem with battery + additional PV...\")\n",
    "\n",
    "try:\n",
    "    # Create an instance of the optimization problem\n",
    "    problem = BatteryPVOptimizationProblem(\n",
    "        pv_profile=pv_profile, \n",
    "        demand_profile=demand_profile,\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    print(f\"Optimization problem defined with:\")\n",
    "    print(f\"  • Variables: {problem.n_var} [{', '.join(map(str, problem.xl))}] to [{', '.join(map(str, problem.xu))}]\")\n",
    "    print(f\"  • Objectives: {problem.n_obj} (IRR and NPV)\")\n",
    "    \n",
    "    # Set up the NSGA-II algorithm\n",
    "    algorithm = NSGA2(\n",
    "        pop_size=config.POPULATION_SIZE,\n",
    "        eliminate_duplicates=True\n",
    "    )\n",
    "    \n",
    "    # Define termination criteria\n",
    "    termination = get_termination(\"n_gen\", config.N_GENERATIONS)\n",
    "    \n",
    "    print(f\"NSGA-II algorithm configured with:\")\n",
    "    print(f\"  • Population size: {config.POPULATION_SIZE}\")\n",
    "    print(f\"  • Generations: {config.N_GENERATIONS}\")\n",
    "    print(f\"  • Total evaluations: {config.POPULATION_SIZE * config.N_GENERATIONS}\")\n",
    "    print(\"Ready to start optimization\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error setting up optimization problem: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc4083c-1eb3-498f-9f67-d83bf86e398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Define callback for tracking optimization progress\n",
    "from pymoo.core.callback import Callback\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "\n",
    "class BestSolutionCallback(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.data = {\n",
    "            \"gen\": [],\n",
    "            \"best_irr\": [],\n",
    "            \"best_npv\": [],\n",
    "            \"batt_irr\": [],\n",
    "            \"batt_npv\": [],\n",
    "            \"pv_irr\": [],\n",
    "            \"pv_npv\": [],\n",
    "            \"time_elapsed\": []\n",
    "        }\n",
    "        self.start_time = time.time()\n",
    "        self.last_print = self.start_time\n",
    "    \n",
    "    def notify(self, algorithm):\n",
    "        gen = algorithm.n_gen\n",
    "        self.data[\"gen\"].append(gen)\n",
    "        \n",
    "        # Get current best objectives\n",
    "        F = algorithm.pop.get(\"F\")\n",
    "        best_irr = -np.min(F[:, 0])  # Convert back from -IRR\n",
    "        best_npv = -np.min(F[:, 1])  # Convert back from -NPV\n",
    "        \n",
    "        self.data[\"best_irr\"].append(best_irr)\n",
    "        self.data[\"best_npv\"].append(best_npv)\n",
    "        \n",
    "        # Calculate time statistics\n",
    "        elapsed = time.time() - self.start_time\n",
    "        self.data[\"time_elapsed\"].append(elapsed)\n",
    "        \n",
    "        # Calculate average time per generation\n",
    "        avg_time_per_gen = elapsed / gen if gen > 0 else 0\n",
    "        \n",
    "        # Estimate time remaining\n",
    "        n_generations = algorithm.termination.n_max_gen\n",
    "        remaining_gens = n_generations - gen\n",
    "        est_remaining_time = avg_time_per_gen * remaining_gens\n",
    "        \n",
    "        # Find battery and PV sizes for best IRR and NPV\n",
    "        X = algorithm.pop.get(\"X\")\n",
    "        best_irr_idx = np.argmin(F[:, 0])\n",
    "        best_npv_idx = np.argmin(F[:, 1])\n",
    "        \n",
    "        best_irr_batt = X[best_irr_idx, 0]\n",
    "        best_irr_pv = X[best_irr_idx, 1]\n",
    "        best_npv_batt = X[best_npv_idx, 0]\n",
    "        best_npv_pv = X[best_npv_idx, 1]\n",
    "        \n",
    "        # Store values for best IRR and NPV\n",
    "        self.data[\"batt_irr\"].append(best_irr_batt)\n",
    "        self.data[\"batt_npv\"].append(best_npv_batt)\n",
    "        self.data[\"pv_irr\"].append(best_irr_pv)\n",
    "        self.data[\"pv_npv\"].append(best_npv_pv)\n",
    "        \n",
    "        # Log progress every 5 generations or if more than 30 seconds passed since last print\n",
    "        current_time = time.time()\n",
    "        time_since_last_print = current_time - self.last_print\n",
    "        \n",
    "        if gen % 5 == 0 or gen == 1 or time_since_last_print > 30:\n",
    "            print(f\"Generation {gen:3d}/{n_generations}: \" \n",
    "                  f\"Best IRR = {best_irr*100:7.2f}% (Batt: {best_irr_batt:.1f} kWh, PV: {best_irr_pv:.1f} kW), \" \n",
    "                  f\"Best NPV = ${best_npv:10,.2f} (Batt: {best_npv_batt:.1f} kWh, PV: {best_npv_pv:.1f} kW), \"\n",
    "                  f\"Time: {timedelta(seconds=int(elapsed))}, \"\n",
    "                  f\"Est. remaining: {timedelta(seconds=int(est_remaining_time))}\")\n",
    "            self.last_print = current_time\n",
    "        \n",
    "        # Print final message when optimization is complete\n",
    "        if gen == n_generations:\n",
    "            print(f\"\\nOptimization complete! Total time: {timedelta(seconds=int(elapsed))}\")\n",
    "            print(f\"Best IRR solution: {best_irr*100:.2f}% (Battery: {best_irr_batt:.1f} kWh, PV: {best_irr_pv:.1f} kW)\")\n",
    "            print(f\"Best NPV solution: ${best_npv:,.2f} (Battery: {best_npv_batt:.1f} kWh, PV: {best_npv_pv:.1f} kW)\")\n",
    "            print(\"Ready for next cell to process and visualize results!\")\n",
    "\n",
    "print(\"Progress tracking callback defined.\")\n",
    "callback = BestSolutionCallback()\n",
    "print(\"Ready to run optimization!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3424fa-7526-45f2-bcdc-9d894c57dff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Run NSGA-II optimization with parallel processing\n",
    "from pymoo.optimize import minimize\n",
    "import time\n",
    "import pickle\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import os\n",
    "\n",
    "print(\"Running NSGA-II optimization with parallel processing...\")\n",
    "total_start_time = time.time()\n",
    "\n",
    "# Configure parallel processing\n",
    "available_cores = multiprocessing.cpu_count()\n",
    "n_processes = min(8, max(2, available_cores - 2))  # Leave 2 cores free for M3 Mac\n",
    "print(f\"Setting up parallel processing with {n_processes} cores out of {available_cores} available\")\n",
    "\n",
    "# Run with specified population size and generations from config\n",
    "pop_size = config.POPULATION_SIZE\n",
    "n_generations = config.N_GENERATIONS\n",
    "print(f\"Population size: {pop_size}, Generations: {n_generations}\")\n",
    "print(f\"Total evaluations: {pop_size * n_generations}\")\n",
    "\n",
    "try:\n",
    "    # Configure parallel processing - latest pymoo approach\n",
    "    from pymoo.core.problem import StarmapParallelization\n",
    "    from multiprocessing.pool import Pool\n",
    "    \n",
    "    # Create the pool with the number of processes\n",
    "    pool = Pool(n_processes)\n",
    "    \n",
    "    # Pass the pool using the starmap parallelization\n",
    "    runner = StarmapParallelization(pool.starmap)\n",
    "    \n",
    "    # Use runner in the minimize function\n",
    "    res = minimize(\n",
    "        problem,\n",
    "        algorithm,\n",
    "        termination,\n",
    "        seed=42,\n",
    "        verbose=False,\n",
    "        callback=callback,\n",
    "        elementwise_runner=runner\n",
    "    )\n",
    "    \n",
    "    # Make sure to close the pool at the end\n",
    "    pool.close()\n",
    "    \n",
    "    # Extract & save Pareto front\n",
    "    solutions = res.X\n",
    "    battery_sizes = solutions[:, 0]\n",
    "    additional_pv = solutions[:, 1]\n",
    "    pareto_F = res.F\n",
    "    irr_vals = -pareto_F[:, 0]  # Convert from -IRR to IRR (higher is better)\n",
    "    npv_vals = -pareto_F[:, 1]  # Convert from -NPV to NPV (higher is better)\n",
    "    \n",
    "    # Create Pareto front DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'battery_kwh': battery_sizes,\n",
    "        'additional_pv_kw': additional_pv,\n",
    "        'irr': irr_vals,\n",
    "        'npv': npv_vals\n",
    "    })\n",
    "    \n",
    "    # Add PV allocation details\n",
    "    allocation_details = []\n",
    "    from pv import allocate_pv_capacity\n",
    "    for pv_kw in additional_pv:\n",
    "        allocated_pv = allocate_pv_capacity(pv_kw, config.PV_OPTIONS)\n",
    "        details = {\n",
    "            'total_additional_pv': pv_kw,\n",
    "            'total_system_pv': config.EXISTING_PV['system_capacity_kw'] + pv_kw\n",
    "        }\n",
    "        \n",
    "        # Add allocation for each option\n",
    "        for option in config.PV_OPTIONS:\n",
    "            option_name = option['name']\n",
    "            allocated = next((p['system_capacity_kw'] for p in allocated_pv if p['name'] == option_name), 0.0)\n",
    "            details[f'{option_name}_kw'] = allocated\n",
    "        \n",
    "        allocation_details.append(details)\n",
    "    \n",
    "    # Convert allocation details to DataFrame and join with main results\n",
    "    allocation_df = pd.DataFrame(allocation_details)\n",
    "    df = pd.concat([df, allocation_df], axis=1)\n",
    "    \n",
    "    # Calculate PI for each solution\n",
    "    pi_values = []\n",
    "    for i, row in df.iterrows():\n",
    "        battery_kwh = row['battery_kwh']\n",
    "        additional_pv_kw = row['additional_pv_kw']\n",
    "        capital_cost = 0\n",
    "        \n",
    "        # Calculate battery cost using formula from config\n",
    "        if battery_kwh > 0:\n",
    "            battery_cost_per_kwh = max(config.BATTERY_COST_FORMULA['minimum'], \n",
    "                                      config.BATTERY_COST_FORMULA['base_cost'] * \n",
    "                                      np.exp(config.BATTERY_COST_FORMULA['exponent'] * battery_kwh))\n",
    "            battery_cost = battery_kwh * (battery_cost_per_kwh + config.BATTERY_COST_FORMULA['installation'])\n",
    "            capital_cost += battery_cost\n",
    "        \n",
    "        # Calculate PV cost\n",
    "        if additional_pv_kw > 0:\n",
    "            # Get all PV allocations\n",
    "            pv_cost = 0\n",
    "            for option in config.PV_OPTIONS:\n",
    "                option_name = option['name']\n",
    "                if f'{option_name}_kw' in row:\n",
    "                    option_kw = row[f'{option_name}_kw']\n",
    "                    if option_kw > 0:\n",
    "                        cost_multiplier = option.get('cost_multiplier', 1.0)\n",
    "                        cost_per_kw = max(config.PV_COST_FORMULA['minimum'], \n",
    "                                         config.PV_COST_FORMULA['base_cost'] * \n",
    "                                         np.exp(config.PV_COST_FORMULA['exponent'] * option_kw))\n",
    "                        pv_cost += option_kw * cost_per_kw * cost_multiplier\n",
    "            capital_cost += pv_cost\n",
    "        \n",
    "        # Calculate PI\n",
    "        pi = row['npv'] / capital_cost if capital_cost > 0 else float('inf')\n",
    "        pi_values.append(pi)\n",
    "    \n",
    "    # Add PI to DataFrame\n",
    "    df['pi'] = pi_values\n",
    "    \n",
    "    # Total runtime\n",
    "    total_elapsed = time.time() - total_start_time\n",
    "    print(f\"\\nOptimization complete! Total runtime: {timedelta(seconds=int(total_elapsed))}\")\n",
    "    print(f\"Average time per evaluation: {total_elapsed/(pop_size * n_generations):.3f} seconds\")\n",
    "    \n",
    "    # Save results\n",
    "    df.to_csv(run_dir / 'pareto_solutions.csv', index=False)\n",
    "    print(f\"✅ Pareto front saved to {run_dir/'pareto_solutions.csv'}\")\n",
    "    \n",
    "    # Display best solutions for each objective\n",
    "    print(\"\\nBest solutions found:\")\n",
    "    print(f\"Best IRR: {df['irr'].max()*100:.2f}% with {df.loc[df['irr'].idxmax(), 'battery_kwh']:.1f} kWh battery and {df.loc[df['irr'].idxmax(), 'additional_pv_kw']:.1f} kW additional PV\")\n",
    "    print(f\"Best NPV: ${df['npv'].max():,.2f} with {df.loc[df['npv'].idxmax(), 'battery_kwh']:.1f} kWh battery and {df.loc[df['npv'].idxmax(), 'additional_pv_kw']:.1f} kW additional PV\")\n",
    "    print(f\"Best PI: {df['pi'].max():.2f} with {df.loc[df['pi'].idxmax(), 'battery_kwh']:.1f} kWh battery and {df.loc[df['pi'].idxmax(), 'additional_pv_kw']:.1f} kW additional PV\")\n",
    "\n",
    "    # Find balanced solution (closest to utopia point)\n",
    "    print(\"\\nFinding balanced solution...\")\n",
    "    # Normalize the objectives to 0-1 scale\n",
    "    df_norm = df.copy()\n",
    "    df_norm['irr_norm'] = (df_norm['irr'] - df_norm['irr'].min()) / (df_norm['irr'].max() - df_norm['irr'].min())\n",
    "    df_norm['npv_norm'] = (df_norm['npv'] - df_norm['npv'].min()) / (df_norm['npv'].max() - df_norm['npv'].min())\n",
    "    \n",
    "    # Calculate the Euclidean distance to the utopia point (1,1)\n",
    "    df_norm['distance'] = np.sqrt((1 - df_norm['irr_norm'])**2 + (1 - df_norm['npv_norm'])**2)\n",
    "    \n",
    "    # Find the balanced solution (minimum distance to utopia)\n",
    "    balanced_idx = df_norm['distance'].idxmin()\n",
    "    print(f\"Balanced solution: IRR = {df.loc[balanced_idx, 'irr']*100:.2f}%, NPV = ${df.loc[balanced_idx, 'npv']:,.2f}\")\n",
    "    print(f\"  with {df.loc[balanced_idx, 'battery_kwh']:.1f} kWh battery and {df.loc[balanced_idx, 'additional_pv_kw']:.1f} kW additional PV\")\n",
    "\n",
    "    # Calculate indices for best IRR, NPV, and PI solutions\n",
    "    best_irr_idx = df['irr'].idxmax()\n",
    "    best_npv_idx = df['npv'].idxmax()\n",
    "    best_pi_idx = df['pi'].idxmax()\n",
    "    \n",
    "    # Save checkpoint of key variables to avoid rerunning optimization\n",
    "    checkpoint = {\n",
    "        'df': df,\n",
    "        'best_irr_idx': best_irr_idx,\n",
    "        'best_npv_idx': best_npv_idx,\n",
    "        'best_pi_idx': best_pi_idx,\n",
    "        'balanced_idx': balanced_idx,\n",
    "        'pareto_front': True\n",
    "    }\n",
    "    \n",
    "    with open(run_dir / 'optimization_checkpoint.pkl', 'wb') as f:\n",
    "        pickle.dump(checkpoint, f)\n",
    "    print(f\"✅ Optimization checkpoint saved to {run_dir/'optimization_checkpoint.pkl'}\")\n",
    "    \n",
    "    print(\"\\nOptimization successful! Ready for detailed analysis in the next cell.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during optimization: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    \n",
    "    # Try to load checkpoint if it exists\n",
    "    try:\n",
    "        checkpoint_path = run_dir / 'optimization_checkpoint.pkl'\n",
    "        if checkpoint_path.exists():\n",
    "            print(\"Attempting to load previous optimization checkpoint...\")\n",
    "            with open(checkpoint_path, 'rb') as f:\n",
    "                checkpoint = pickle.load(f)\n",
    "                df = checkpoint['df']\n",
    "                best_irr_idx = checkpoint['best_irr_idx']\n",
    "                best_npv_idx = checkpoint['best_npv_idx']\n",
    "                best_pi_idx = checkpoint.get('best_pi_idx')  # Handle older checkpoints without PI\n",
    "                balanced_idx = checkpoint.get('balanced_idx')  # Handle older checkpoints\n",
    "                \n",
    "                print(\"✅ Checkpoint loaded successfully\")\n",
    "                print(f\"Best IRR: {df['irr'].max()*100:.2f}% with {df.loc[best_irr_idx, 'battery_kwh']:.1f} kWh battery and {df.loc[best_irr_idx, 'additional_pv_kw']:.1f} kW additional PV\")\n",
    "                print(f\"Best NPV: ${df['npv'].max():,.2f} with {df.loc[best_npv_idx, 'battery_kwh']:.1f} kWh battery and {df.loc[best_npv_idx, 'additional_pv_kw']:.1f} kW additional PV\")\n",
    "                if 'pi' in df.columns and best_pi_idx is not None:\n",
    "                    print(f\"Best PI: {df['pi'].max():.2f} with {df.loc[best_pi_idx, 'battery_kwh']:.1f} kWh battery and {df.loc[best_pi_idx, 'additional_pv_kw']:.1f} kW additional PV\")\n",
    "                if balanced_idx is not None:\n",
    "                    print(f\"Balanced solution: IRR = {df.loc[balanced_idx, 'irr']*100:.2f}%, NPV = ${df.loc[balanced_idx, 'npv']:,.2f}\")\n",
    "                    print(f\"  with {df.loc[balanced_idx, 'battery_kwh']:.1f} kWh battery and {df.loc[balanced_idx, 'additional_pv_kw']:.1f} kW additional PV\")\n",
    "    except Exception as load_err:\n",
    "        print(f\"Error loading checkpoint: {load_err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e259cb48-e2df-456b-9be0-e0a3a535ae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Process and Visualize Optimization Results\n",
    "print(\"Processing and visualizing optimization results...\")\n",
    "\n",
    "try:\n",
    "    # Check if we have results to process\n",
    "    if 'df' not in locals() or df is None:\n",
    "        # Try to load from checkpoint\n",
    "        checkpoint_path = run_dir / 'optimization_checkpoint.pkl'\n",
    "        if checkpoint_path.exists():\n",
    "            print(\"Loading results from checkpoint...\")\n",
    "            with open(checkpoint_path, 'rb') as f:\n",
    "                checkpoint = pickle.load(f)\n",
    "                df = checkpoint['df']\n",
    "                print(\"Checkpoint loaded successfully!\")\n",
    "        else:\n",
    "            raise ValueError(\"No optimization results available. Please run the optimization first.\")\n",
    "    \n",
    "    # Ensure lowercase column names for consistency\n",
    "    df.columns = [col.lower() for col in df.columns]\n",
    "    \n",
    "    # Find best IRR and NPV indices\n",
    "    if 'irr' in df.columns:\n",
    "        best_irr_idx = df['irr'].idxmax()\n",
    "        best_npv_idx = df['npv'].idxmax()\n",
    "        print(f\"Best IRR: {df.loc[best_irr_idx, 'irr']*100:.2f}% (Battery: {df.loc[best_irr_idx, 'battery_kwh']:.1f} kWh, PV: {df.loc[best_irr_idx, 'additional_pv_kw']:.1f} kW)\")\n",
    "        print(f\"Best NPV: ${df.loc[best_npv_idx, 'npv']:,.2f} (Battery: {df.loc[best_npv_idx, 'battery_kwh']:.1f} kWh, PV: {df.loc[best_npv_idx, 'additional_pv_kw']:.1f} kW)\")\n",
    "    \n",
    "    # Run the comprehensive results analysis\n",
    "    from results import run_results_analysis\n",
    "    \n",
    "    results = run_results_analysis(\n",
    "        df=df,\n",
    "        callback=callback,\n",
    "        pv_profile=pv_profile,\n",
    "        demand_profile=demand_profile,\n",
    "        config=config,\n",
    "        run_dir=run_dir\n",
    "    )\n",
    "    \n",
    "    print(\"\\nOptimization analysis complete!\")\n",
    "    print(f\"All results have been saved to: {run_dir}\")\n",
    "    \n",
    "    # Display paths to key result files\n",
    "    print(\"\\nKey result files:\")\n",
    "    print(f\"- Summary report: {run_dir/'summary_report.txt'}\")\n",
    "    print(f\"- Pareto front visualization: {run_dir/'plots'/'pareto_front_irr_npv.png'}\")\n",
    "    print(f\"- Solution comparison: {run_dir/'data'/'solution_comparison.csv'}\")\n",
    "    print(f\"- Best IRR solution details: {run_dir/'data'/'best_irr_summary.csv'}\")\n",
    "    print(f\"- Best NPV solution details: {run_dir/'data'/'best_npv_summary.csv'}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error processing results: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
